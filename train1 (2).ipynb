{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLLeh5XvcVJt",
    "outputId": "83aea8ea-9518-48f4-f475-a7590a7dc81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')\r\n",
    "os.listdir('/content/drive/MyDrive/anhECG/ecg_img/train')\r\n",
    "os.chdir('/content/drive/MyDrive/anhECG')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mu820DZ4caXj",
    "outputId": "91ce0ea2-bd4a-4c61-daac-03d5feb144ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37178, 5)\n",
      "1.F\n",
      "2.N\n",
      "3.Q\n",
      "4.S\n",
      "5.V\n",
      "Epoch 1/50\n",
      "1162/1162 - 76s - loss: 0.8156 - accuracy: 0.9442 - val_loss: 0.3244 - val_accuracy: 0.9273\n",
      "Epoch 2/50\n",
      "1162/1162 - 75s - loss: 0.1635 - accuracy: 0.9651 - val_loss: 0.1437 - val_accuracy: 0.9576\n",
      "Epoch 3/50\n",
      "1162/1162 - 75s - loss: 0.1979 - accuracy: 0.9629 - val_loss: 0.2153 - val_accuracy: 0.9486\n",
      "Epoch 4/50\n",
      "1162/1162 - 75s - loss: 0.1643 - accuracy: 0.9666 - val_loss: 0.2375 - val_accuracy: 0.9270\n",
      "Epoch 5/50\n",
      "1162/1162 - 75s - loss: 0.1398 - accuracy: 0.9688 - val_loss: 0.3610 - val_accuracy: 0.8938\n",
      "Epoch 6/50\n",
      "1162/1162 - 75s - loss: 0.1500 - accuracy: 0.9697 - val_loss: 0.2616 - val_accuracy: 0.9150\n",
      "Epoch 7/50\n",
      "1162/1162 - 75s - loss: 0.1396 - accuracy: 0.9709 - val_loss: 0.4239 - val_accuracy: 0.8754\n",
      "Epoch 8/50\n",
      "1162/1162 - 75s - loss: 0.1411 - accuracy: 0.9706 - val_loss: 0.1648 - val_accuracy: 0.9608\n",
      "Epoch 9/50\n",
      "1162/1162 - 75s - loss: 0.1202 - accuracy: 0.9737 - val_loss: 0.4839 - val_accuracy: 0.9072\n",
      "Epoch 10/50\n",
      "1162/1162 - 75s - loss: 0.1171 - accuracy: 0.9726 - val_loss: 0.1913 - val_accuracy: 0.9352\n",
      "Epoch 11/50\n",
      "1162/1162 - 75s - loss: 0.1412 - accuracy: 0.9729 - val_loss: 0.2460 - val_accuracy: 0.9309\n",
      "Epoch 12/50\n",
      "1162/1162 - 75s - loss: 0.1637 - accuracy: 0.9682 - val_loss: 0.2153 - val_accuracy: 0.9418\n",
      "Epoch 13/50\n",
      "1162/1162 - 75s - loss: 0.1505 - accuracy: 0.9711 - val_loss: 0.2389 - val_accuracy: 0.9351\n",
      "Epoch 14/50\n",
      "1162/1162 - 75s - loss: 0.1428 - accuracy: 0.9743 - val_loss: 0.6494 - val_accuracy: 0.8792\n",
      "Epoch 15/50\n",
      "1162/1162 - 75s - loss: 0.1411 - accuracy: 0.9695 - val_loss: 0.3642 - val_accuracy: 0.8922\n",
      "Epoch 16/50\n",
      "1162/1162 - 75s - loss: 0.1354 - accuracy: 0.9717 - val_loss: 0.3205 - val_accuracy: 0.9187\n",
      "Epoch 17/50\n",
      "1162/1162 - 75s - loss: 0.1382 - accuracy: 0.9702 - val_loss: 0.3130 - val_accuracy: 0.8920\n",
      "Epoch 18/50\n",
      "1162/1162 - 75s - loss: 0.1290 - accuracy: 0.9737 - val_loss: 0.2222 - val_accuracy: 0.9361\n",
      "Epoch 19/50\n",
      "1162/1162 - 75s - loss: 0.1321 - accuracy: 0.9716 - val_loss: 0.2783 - val_accuracy: 0.9507\n",
      "Epoch 20/50\n",
      "1162/1162 - 76s - loss: 0.1037 - accuracy: 0.9774 - val_loss: 0.2907 - val_accuracy: 0.9421\n",
      "Epoch 21/50\n",
      "1162/1162 - 75s - loss: 0.1098 - accuracy: 0.9751 - val_loss: 0.2795 - val_accuracy: 0.9298\n",
      "Epoch 22/50\n",
      "1162/1162 - 75s - loss: 0.1023 - accuracy: 0.9766 - val_loss: 0.2593 - val_accuracy: 0.9269\n",
      "Epoch 23/50\n",
      "1162/1162 - 75s - loss: 0.0998 - accuracy: 0.9790 - val_loss: 0.2572 - val_accuracy: 0.9564\n",
      "Epoch 24/50\n",
      "1162/1162 - 75s - loss: 0.1197 - accuracy: 0.9756 - val_loss: 0.5025 - val_accuracy: 0.8913\n",
      "Epoch 25/50\n",
      "1162/1162 - 75s - loss: 0.1101 - accuracy: 0.9751 - val_loss: 0.3170 - val_accuracy: 0.8773\n",
      "Epoch 26/50\n",
      "1162/1162 - 75s - loss: 0.1098 - accuracy: 0.9762 - val_loss: 0.3051 - val_accuracy: 0.9181\n",
      "Epoch 27/50\n",
      "1162/1162 - 75s - loss: 0.0961 - accuracy: 0.9770 - val_loss: 0.3595 - val_accuracy: 0.9382\n",
      "Epoch 28/50\n",
      "1162/1162 - 75s - loss: 0.1519 - accuracy: 0.9689 - val_loss: 0.3460 - val_accuracy: 0.8993\n",
      "Epoch 29/50\n",
      "1162/1162 - 75s - loss: 0.1336 - accuracy: 0.9730 - val_loss: 0.3112 - val_accuracy: 0.9075\n",
      "Epoch 30/50\n",
      "1162/1162 - 75s - loss: 0.1094 - accuracy: 0.9772 - val_loss: 0.4685 - val_accuracy: 0.8998\n",
      "Epoch 31/50\n",
      "1162/1162 - 75s - loss: 0.1080 - accuracy: 0.9752 - val_loss: 0.3175 - val_accuracy: 0.9345\n",
      "Epoch 32/50\n",
      "1162/1162 - 75s - loss: 0.1105 - accuracy: 0.9764 - val_loss: 0.4442 - val_accuracy: 0.8972\n",
      "Epoch 33/50\n",
      "1162/1162 - 75s - loss: 0.0986 - accuracy: 0.9776 - val_loss: 0.3308 - val_accuracy: 0.9067\n",
      "Epoch 34/50\n",
      "1162/1162 - 75s - loss: 0.1175 - accuracy: 0.9786 - val_loss: 0.2944 - val_accuracy: 0.9239\n",
      "Epoch 35/50\n",
      "1162/1162 - 75s - loss: 0.0934 - accuracy: 0.9774 - val_loss: 0.3545 - val_accuracy: 0.9130\n",
      "Epoch 36/50\n",
      "1162/1162 - 75s - loss: 0.0892 - accuracy: 0.9783 - val_loss: 0.3074 - val_accuracy: 0.9245\n",
      "Epoch 37/50\n",
      "1162/1162 - 75s - loss: 0.1273 - accuracy: 0.9765 - val_loss: 0.1558 - val_accuracy: 0.9754\n",
      "Epoch 38/50\n",
      "1162/1162 - 75s - loss: 0.1417 - accuracy: 0.9707 - val_loss: 0.4021 - val_accuracy: 0.9646\n",
      "Epoch 39/50\n",
      "1162/1162 - 75s - loss: 0.1326 - accuracy: 0.9750 - val_loss: 0.3353 - val_accuracy: 0.9464\n",
      "Epoch 40/50\n",
      "1162/1162 - 75s - loss: 0.1402 - accuracy: 0.9772 - val_loss: 0.3114 - val_accuracy: 0.9322\n",
      "Epoch 41/50\n",
      "1162/1162 - 75s - loss: 0.1006 - accuracy: 0.9767 - val_loss: 0.3445 - val_accuracy: 0.9484\n",
      "Epoch 42/50\n",
      "1162/1162 - 75s - loss: 0.0837 - accuracy: 0.9807 - val_loss: 0.3947 - val_accuracy: 0.9020\n",
      "Epoch 43/50\n",
      "1162/1162 - 75s - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.4272 - val_accuracy: 0.9263\n",
      "Epoch 44/50\n",
      "1162/1162 - 75s - loss: 0.0871 - accuracy: 0.9793 - val_loss: 0.5488 - val_accuracy: 0.9247\n",
      "Epoch 45/50\n",
      "1162/1162 - 75s - loss: 0.1431 - accuracy: 0.9757 - val_loss: 0.6072 - val_accuracy: 0.9427\n",
      "Epoch 46/50\n",
      "1162/1162 - 75s - loss: 0.0872 - accuracy: 0.9804 - val_loss: 0.4469 - val_accuracy: 0.9408\n",
      "Epoch 47/50\n",
      "1162/1162 - 75s - loss: 0.1068 - accuracy: 0.9786 - val_loss: 0.3244 - val_accuracy: 0.9440\n",
      "Epoch 48/50\n",
      "1162/1162 - 75s - loss: 0.0866 - accuracy: 0.9795 - val_loss: 0.3506 - val_accuracy: 0.9389\n",
      "Epoch 49/50\n",
      "1162/1162 - 75s - loss: 0.0909 - accuracy: 0.9785 - val_loss: 0.6061 - val_accuracy: 0.8902\n",
      "Epoch 50/50\n",
      "1162/1162 - 75s - loss: 0.1050 - accuracy: 0.9781 - val_loss: 0.6650 - val_accuracy: 0.9370\n",
      "Thoi gian chay 3768.3251259326935 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\ntest_loss, test_acc = my_model.evaluate(X_test, y_test, verbose=2)\\nprint('Test accuracy:', test_acc)\\nprint('Test Lost:', test_loss)\\n\\n#predictions = my_model.predict(X_test)\\n#print(predictions)\\n#score = my_model.accuracy_score(encoder.change(y_test), change(predictions))\\n#print(score)\\n\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from keras.applications.vgg16 import VGG16\r\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\r\n",
    "from keras.models import Model\r\n",
    "from keras.callbacks import ModelCheckpoint\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import random\r\n",
    "import os\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from keras.models import  load_model\r\n",
    "import time\r\n",
    "# Khai b√°o\r\n",
    "X_train=[]\r\n",
    "y_train=[]\r\n",
    "\r\n",
    "X_test=[]\r\n",
    "y_test=[]\r\n",
    "\r\n",
    "width,height=128,128\r\n",
    "#batch_size = 64\r\n",
    "\r\n",
    "X_train = np.load(\"xtrain.npy\")\r\n",
    "y_train = np.load(\"ytrain.npy\")\r\n",
    "X_test = np.load(\"xtest.npy\")\r\n",
    "y_test = np.load(\"ytest.npy\")\r\n",
    "\r\n",
    "encoder = LabelBinarizer()\r\n",
    "y_train =encoder.fit_transform(y_train)\r\n",
    "y_test =encoder.fit_transform(y_test)\r\n",
    "\r\n",
    "# # y_train = np_utils.to_categorical(y_train,n_classes)\r\n",
    "# # y_test = np_utils.to_categorical(y_test,n_classes)\r\n",
    "\r\n",
    "print(y_train.shape)        \r\n",
    "\r\n",
    "for (i,lab) in enumerate(encoder.classes_):\r\n",
    "    print(\"{}.{}\".format(i+1,lab))\r\n",
    "\r\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])  \r\n",
    "#filepath=\"Luu/weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\r\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_weights_only=False,\r\n",
    "                             #period=1,verbose=1,save_best_only=False)\r\n",
    "#callbacks_list = [checkpoint]\r\n",
    "\r\n",
    "base_model = VGG16(input_shape=(128,128,3),weights='imagenet', include_top=False)\r\n",
    "    # Dong bang cac layer\r\n",
    "for layer in base_model.layers:\r\n",
    "        layer.trainable = False\r\n",
    "    # Them cac layer FC va Dropout\r\n",
    "x = Flatten(name='flatten')(base_model.output)\r\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\r\n",
    "x = Dropout(0.4)(x)\r\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\r\n",
    "x = Dropout(0.4)(x)\r\n",
    "x = Dense(5, activation='softmax', name='predictions')(x)\r\n",
    "    # Compile\r\n",
    "my_model = Model(base_model.input, x)\r\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "#print(my_model.summary())\r\n",
    "start = time.time()\r\n",
    "history = my_model.fit(\r\n",
    "  X_train,y_train,\r\n",
    "  validation_data=(X_test,y_test),\r\n",
    "  epochs=50,verbose=2,#shuffle=True, \r\n",
    "  #batch_size=64\r\n",
    "  #callbacks=callbacks_list\r\n",
    ")\r\n",
    "\r\n",
    "my_model.save(\"model_5004bat32.h5\")\r\n",
    "np.save('my_history5004bat32.npy', history.history)\r\n",
    "print(\"Thoi gian chay\", time.time()-start,\"seconds\")\r\n",
    "\"\"\"\r\n",
    "test_loss, test_acc = my_model.evaluate(X_test, y_test, verbose=2)\r\n",
    "print('Test accuracy:', test_acc)\r\n",
    "print('Test Lost:', test_loss)\r\n",
    "\r\n",
    "#predictions = my_model.predict(X_test)\r\n",
    "#print(predictions)\r\n",
    "#score = my_model.accuracy_score(encoder.change(y_test), change(predictions))\r\n",
    "#print(score)\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
