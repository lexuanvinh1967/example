{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 2.3952 - accuracy: 0.1030\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 2.3847 - accuracy: 0.0900\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3204 - accuracy: 0.1070\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3351 - accuracy: 0.0890\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 2.3208 - accuracy: 0.1040\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 2.3136 - accuracy: 0.1030\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3072 - accuracy: 0.1040\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.2991 - accuracy: 0.1060\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 2.3108 - accuracy: 0.1020\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 2.3018 - accuracy: 0.1080\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3095 - accuracy: 0.1090\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3037 - accuracy: 0.1120\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 2.3015 - accuracy: 0.1050\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 2.3023 - accuracy: 0.1160\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 2.2995 - accuracy: 0.0920\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.2968 - accuracy: 0.1460\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 2.3065 - accuracy: 0.1180\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 2.3008 - accuracy: 0.1030\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.2998 - accuracy: 0.1050\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 2.2944 - accuracy: 0.1270\n",
      "100/100 [==============================] - 0s 654us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 331us/step - loss: 0.7205 - accuracy: 0.4800\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.7195 - accuracy: 0.4820\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.7005 - accuracy: 0.5210\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.7020 - accuracy: 0.5130\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.6989 - accuracy: 0.5020\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6893 - accuracy: 0.5320\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6964 - accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.7035 - accuracy: 0.4790\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.6935 - accuracy: 0.5200\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6966 - accuracy: 0.5010\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6910 - accuracy: 0.5240\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6973 - accuracy: 0.4840\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6972 - accuracy: 0.5100\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.6915 - accuracy: 0.5370\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.6937 - accuracy: 0.5200\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6911 - accuracy: 0.5140\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6918 - accuracy: 0.5210\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6884 - accuracy: 0.5410\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6958 - accuracy: 0.4780\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6907 - accuracy: 0.5320\n",
      "100/100 [==============================] - 0s 637us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 37s 0us/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'elephant.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-933357ae2878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'elephant.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'elephant.jpg'"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
