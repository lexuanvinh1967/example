{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinh dữ liệu: 300 điểm trong $R^2$, 3 loại 0,1,2 ứng với 3 màu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # number of points per class\n",
    "d0 = 2 # dimensionality\n",
    "C = 3 # number of classes\n",
    "X = np.zeros((d0, N*C)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*C, dtype='uint8') # class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(C):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "  X[:,ix] = np.c_[r*np.sin(t), r*np.cos(t)].T\n",
    "  y[ix] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgpklEQVR4nO3df5RU5XkH8O8su8vMzqKgGMAkxsqJEQLVc5BzEkPAY1ub1BIMJcc9tBiNqYaaWElIjjFGLBRbToKatDlg0iiBSqNLhWoUYrVVAZsKQuiKLpqlLKiwrMAi7M7szo/bP97e3Tt37nvve2fuzHvvzPdzzh50dnb2zsI+88zzPu/zxgzDABERVV+D7gsgIqpXDMBERJowABMRacIATESkCQMwEZEmDMBERJo0+rnz+PHjjYsvvrhCl0JEVJtee+219w3DuMB+u68AfPHFF2P37t3BXRURUR2IxWLdTrezBEFEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMAATEWnCAExEpAkDMBGRJgzARESaMABHXG9/L+asm4O9R/dizro5OHz6sO5LIiJFDMARt3b3Wuw4vAML/3UhdhzegTu23qH7kohIEQNwhGVyGTz03w8hb+TReaITeSOP57qewytHXtF9aUSkgAE4xMzygqyssKVzCzK5TMFtqWwKf/n0XyJv5KtxiURUBgbgEDPLC7KywsrtK3Fm6EzR7d193Xjsfx6r9OXVvlQKWLcO+NKXxMe6dUA6rfuqqIbEDMNQvvOVV15p7N69u4KXQ6ZMLoOJqyfiZOokEo0JPH/j87jqo1cNf37v0b2Y9egsDGQGHL9+XHwcjiw5gmRzslqXXFt27QKuuQY4e7bw9jFjgBdeAGbO1HNdFEmxWOw1wzCutN/ODDikrOUFp7LCqp2rkM7Ks7F0No2V21dW/DprUioF/NEfFQdfADhzBrj2WmbCFAgG4JAx677LXlxWUF6wlxX29+53rfOmsik81/VcRa+1Zj3+ODDg/M4CgAi+Tz5ZveuhmtWo+wKo0Nrda7G9ezsaYoWvjf2Zfvz1tr/G/CnzkWxOomNxB9r3t+OWp24ZDtRTL5iKjsUdRV9LPuzaBSxeDGQy8vuk08DBg+K/Uylg82agqwuYPBmYPx+Ix6tzrRR5/E0NEbOtzICBnJEr+ry9rGBfhOPiW5lSKbXyQjwOXHKJCNYXXgjcdhuwbJn4c9IkcTuRAgbgEHFqK7OylhX2Ht2Lt0++XfB5M0vuH+qv6HXWrM2bgWzW+37pNPChD4lg3dcnasWGIf7s62ONmJQxAIeIPaNNNiXR0tQCAEg0JrDzKzux+1bRhSJbhOPiWxk6O50X3pzMmycP1tksa8SkhAE4JGQZrdlmZu+EkC3C1e3iWyoFbNwIrFgh/vSbge7aBaxerX7/wUF5sO7vH6kRE7ngIlxIeLWVASM13kWXL0LH4o4qXVkE7Nol3vZnsyL4JZPA7bcDzz2n1q9r1n7dOh/scsU1+mHJpKgRO32fIBbsuPBXM7gRIySmr5mO14+/7nm/uthg4SfApFJiIayvr/hzY8cCR496B6eNG4GvflU8VhCcvq/Ti0Rj48iLhOpz9nocCiXZRgxmwCFhz2jbNrWh/Y32ojKDWeO9/w/ur+blVZY1+ADAAw+4Z7PW+x87Jq/FptPAokXAF7/oHsQ7O8sPvrFYYTC0fi8zw7a+SJjli2uvBZ5+Gpg71zuDP3kSuPrqwkzd+jgqLzYUKgzAIeVV462ZAGzN6JxqqvYA09FRmAE2NQFDQ86PnU4DmzYBv/oVcMstwN13A9/+dnGQOnGi/OdxzTXAV77iHOjduisyGeCP/9g7qO7aVRx8rcyFv4ULy34qVD1chAuYbIKZ12Qzuz237sF5ifMAjHRAGMsMHF96HMnmZG0MXrdmhl7dB9ks8MtfFrd+yYKvVTotPu69F5g4sbhP9/zzS30GQmurCL4LFzpnoF1d4sXCSX+/dzeFSo26vx946y3/105aMQAHTDbBzGuymZ1sFoTfxwk11b5bQASYZ55Rv7/M6dPFfbqXXeb91j2ZFGUGJ42NIvOVmTxZfL3sa2UvImY3hcrPyTCAH/yAm0AihgE4QNYB6dbB6LLb3Tjtclv/2/W+HyfU3DJDOzOAud2/uVntsex9ul5dBF/9KvDTnwIvvywW2FpbRTBubRX/b6/52s2fLwKt7FpkzG4K1Z/TwAA3gUQMA3CAZFmr12QzO1lP8Ne3fh1D2SHlxwk9t8zQrr8fmDJFfv9kUgTKBQuA0aO9H8vapxuPiyA6duzI4zc3Ay0twPbtwM9+JsoLs2YB770HPPwwsHy5+PPoUe/uA+vjm8FbhZlZ+/k5WV9cyumNLrevmpRwES5AstkMq/9rtePtiy5f5Pg4sp7ggcwADIy0DXo9TmiZXQydnWo1XEC8xf7xj+WZZFPTyEaKSZPERgkZpz7dmTNFcN28WQTnSy5xzowTidIWuqZNAx58UJRRDh8G9u2TX2M8PhK043FxHbffrvZ9zBeXcnqjy+2rJmXsAw6IbED6OaPPQSaXQSpb2Obk1s+r2hPs9TihZP/ljsWAvGIW39oKfOc7xW1q9j5Y83s49QYD6v3BQbE/Z7fODUBk8Rs2yPuI3RYsW1uBf/gHYMmS0nqjg+irpiLsA64wWdbaP9TvOtnMqZ3MaZdbTfQFO/XD+kgAhgO2V6ZqZrM//CFw//3iewwOiuDk1KdbSU7P2S34traKvmX79Vkz9AMHxHNz6oow3yG4tb1961uiG2TyZODznwe2bh3ZADI05N2VwVa3wDAAB0TWt+sUfAH3ft7e/l4saF+ADV/cgIvOvcj18SPVF/z44+XVEs3SgUoZIJEAvv99YOlS77JCJfnp9ADcOyqsz/tP/1S+I27bNve2t3/6JxGI43Hx95FIiBeKZFI8nqw0whkXwTMMQ/ljxowZBnlb/uJyo+FvGox5/zLPOH72uDH70dnGnvf2GLMfnW1093X7+vqa8eqrhhGPG4bIR0v7GDvWMFIp3c/En+XLDSMWkz+n5mbx+dZW8fxefVX9sQcGDOOxxwxjxQrxp/mzeewx8Xjl/KydPlpbxWOTbwB2Gw4xlTXggNkP0/zz6X+OR377CC4971K8dfItzL10Lra0bVH+evthnJHkVld009wsMrUozzvYuFEManeq2yaTwJe/LBYNg8zO02nxmH5/3l5YAy4Za8BVYm85e+S3jyBv5NF5ohMAhvt3ZUHVqWUt8scM+X0bDgDnnAP86EfAO+/oKR0Exa2DwezcKPV5yQb4mB0U1hKFn1o7IB6jsbG4vBHFv4MQYwAOmL0VzV639Qqqsla2ULaayQKA/fYDB9Q3XABioe2ZZ0TfbdQ5BcMgAppXq5h10W7zZmDLFn8vgjfeCMyZo692XicYgAPktIHCiSyouh0zZB7GGRqyAPDQQ8Cddxbens+LhR7VebstLaJXtlao9hir8pquZpYJzEW7ri4xlMiPiRNFN4b5QvrkkwzCFcAAHCCVoeqAPKh6HTMUmk4HtwBw002F9zVvV939BYhAXWur7aVu4HDiVtJxahWbPFm0t6ket5RIiAz9wgu5GaPCIlxYDB9Zq5gTp7PbInPMUCk13Xhc1DxVyE6UIMFrupr9xcttFoWT5mZRm3Y6cPTqq8UJ0NyeHAhmwAGybqCY8MMJON5/XHpfp/7dyBwz5GeIjimdBq6/Hnj2WfdtwoD3dLF6Z86GkHVW2F+8ZHVoQLwzMYzC2vQNN4g5F04GBsQcjNZWZsQBYAZcAZlcBtm8yBCts3yNZQaWX70cDbEGzPvEvOETjiPHz3AYUzIpdl2NGiW/j+p0sXrnltHKXrzMOrR1kFBvL9DTU3jbwYPAL37hfQ1mRjx7NrBuHbPhErEPuALa97fjlqduGe5mmHrBVHQs7kAun6uNHt9S+kzHjAEaGsRWV+vxP4mEyMIWLRK/zFzoUVPu2XCyDpaNG8Vwea93KVbW1jdmw47YB1xFslayeGO8Nnp8zV82tyNygJFz0vJ58QvtNAMhFgPefVdkvqSunM4Ktxa2ri5/wRcYOXGE59L5FrHf/PCTtZJ9Y+s3sPzl5Y6BOZJmzgSeekr++ZYWcQ5bPi9+0WUDaBoaRF2Y/DM7K+65R34ckp39GCjrAtu11wIf/agoBZXCPuiePDEAB0zWSnZm6Aw6ezsLbjPb0fqHfC5ohUEqJfpEZTZtEh8DA+7Tvzjgpbq8WtgAfx0TVvy79I0BOGCyVrK8kUfWKP6H79SOFgmPPw6cOSP//Ny5an2nbDmrLq8WtnfeKT69o7VVfIwZ437aCP8ufWMADljH4o7hjocnFjyBMc1jXO8fuh5fVW7lBwDI5dR6hdlyVl1uHSxmAHXrmFi7Vl7q4N+lb+yCqKAr1l6BfT37hv8/2ZTEmuvWhHOugx+7dgGf+YyYVFYqrpzr4dbBojrtrNwOjDrELogqsA5SPzFwIjpzHfwwF3HKDb5r1gBtbVwxr7YghgPZOzA+8hFx+7ZtwNtvO3djyNre6hwDcIDW7l6LHYd34I6tdyDeGI/GXAe/StmGbDJPGo5gpjRxongH7mTCBODYsepeT1mCGA5kdmCoHODJQz6lWIIIiH2Q+qQxk3DwlPOK8IxJM6K7C27FCjELwO982eZmcWx8OfNvNfKaJeT3x1ETVA7wNAwe8gl5CYKLcAHZ0rkFQ1nRbpXKphBvjCN3b65o+7GxzIhu8AVK24YMiMw3QsF34kQRdM0PcqAylU3lPnWMATggK7evxNnMSNuVuckik8vgof9+CHkjP3waRqT5nazV1CSC79NPhz74WoOurNxAFipT2fxObqszDMABcBuk/svXf1m0/Vh1ZGUomYs4Y8eKwOrFXKybO1fUAkPKrcZLEiotbZMni3qxk0Si7vuGWQMOQNumNjyx/wkYKPxZJhoTGNM8BscHRsZShr4VTXW1+uRJsW1V9ZQLQHvNr5JBti5rwCotbakUcP75zj+gWEz8O6qDOSCsAVfQ/t79RcEXEBlv70BvwW3W7ce9/b2Ys24ODp8OyfE7u3aJBZPbbhMLbbfdJn7BnDLXbdvEnAc/qljzs9dwK11WiMXE96wr1ndD1l1z1pGiW7fKX3Dj8bqfA8I2tACsv349Zj06CwOZwmywqaFpeC6wldmKlmhMDLetuR1VXxWq54yZGfLPf+5/BmwVan46Swk9PSMLdg0N8tenyLWtufFqaevqkv87SafrvgbMABwA2QCebD4rzYx/3fVrHOo7VLA4p3U2sMpq9cc/PtLPqXq+mFWFZgWEsX7r9ubAGqhNkQ7KsvPuUinxpJqanAcycXYESxBBkA3gMWDgkrGXFM2D+MKlX8Bdn7mroG1N++Kc12r1gQOFYwxLcfYscNFFJV+iTNiCbylq4TkUMMtZv/iFfBoeZ0cwAw6C21luV6y9Agf7Ct9mbX17K97ofcOxbU3b4pzXOWPvv1/6DjiruXMLF+K4RbX2OJWzrFpb/W19rmHMgCvIqT0NADJGBr879buC27TPBvY6Z+z88+UZciwGfPKTYsHOy9mzwJw54hyxHTvUF/0kanHhy2kB0fyIxPN1K2c1NwM33ihehOt8GzLAAFxRstqwjNbZwF4r2pdd5t7zuXQpcPq09/fJZoFXXwVuvhn47GflJzMoLPCFsfYbBLfnFInn61bOGhoCxo+v+8zXxBJEBclqwzJOR9VXlduK9vTpYoCKEzNzDmrPrrno57SwYxGJYFSP3MpZAPCDH4z8m6nzshM3YlRB26Y2tL/R7hmMx8XH4ciSI+EdVek2B3bbttKG9DiJxYA/+zPg939f/guaSuGmlsfxBTyFC/Eu3sWH8RS+gMfRhkGo/zJPmBCeQG7+6CI/+Ef11Gzz0NY6mCUs24jBAFwF09dMx+vHX/e8X0OsAV+b8TX85LqfVOGqSmQumtkz5I0bRQ231A4Ju1GjxKkayaRoY/rmN8W25p4e0ZGxYweMXA4A0NsCzGsDBhuBHGL4XX4qBtqfBU67d1yYrV9eoyaB6gTpmgnAgHix9jo126qlpaZPx2YADpEpP5mCzvc7HT937uhz0XdXX3UvKAiqWU8FrJgN3Hs1AGvgSp0HPNEOtM0H/nkr8M6nhz9ViZ7bIOrRkQ3Ask6We+8V40tVtbQAL75Yk5kwtyJrZN9yvHDawoLxlEP3DOG8xHkAgKHcUDQnplkX8aoo0wA8+CmIf8kxy0fiJHDDfGD0aTTdOgfdfYdhGCJ4dXQFvwX82DHx2GbGXDfctq9fdpm/I+4HBpQXYGsFA3AVWE/KsI+nfOatZ3D52ssxmB0EEJJNGaWaORN48EFRMqiSLZcBKadvFwMQPw3EgEw+g8/98+eGP2X9+wjasWOlB2GV2cOhCvDWfl+nTpY/+RP/R9zX2YxgBuAKswfcVTtWFYynvPnfbsab77+J/sxI2465KSOSjhwJZsOGopWzgbRCvH/z/TfRvr9dOp85yMFIZjbs9uE3kE6YIL4uVNuVvbavP/useFfkJwuusxnBDMAVtqVzS0HA/dvtf4szQ2eGP2+flgaEYFNGOUo9MaMEeycCB853uYMtm2zb1IYnO590fLdRyazYid96cVg6NQqoDFufNs1fFlxn8yEYgCts5faVBQF3MDeo9HVaN2WUw++JGWVY9Rkg7eNb5ZHH4qcXF7zb6Hy/Ew+88kBtnVpSLSoD2f0e4lpn8yEYgCtIthVZhbkpI3KcdtRZtbaK+zQ3A6NHl/Wt9n8IRVmul1ODpwr+P2/kcdcLd2EoV53BSOY245rgtX19/nz3LBkQ/w6c5gjXCe6EqyC/W5GBCGzGUGHfUfeRj4jb33lnpHfYMMTnX34Z2LBBzG/0ufrdseb//+P/e0in/8tnlfqt7XJGDmeHqjMYKZSlhFKZL7ayzTnxuPeQpy9/WXRN2OcI1wn2AVeQ2waMcfFxOD14uijTSjQmcOen7sSSTy3BgvYF2PDFDbjoXPURjr39vSV9nVZmH+mBA2Lq2vjx4pd49WqxGaO/X3RWNDSIDRqxWPEvu6139Ny/PxcfDH5Q8iVV6oWwnOw3dP2/JtnmHEDt2KI6CLqyPmBmwBXkNqZy+prpOHX8VNHtZumh1NMyrItJ2k/ZUCUb6L10afEvtpk5O/2yW1x07kUlZcMmswavbS5HlMj+/gC1LLmOMQMOoUwug4mrJ+Jk6iQSjQk8f+Pzjqdl2LNd1a+rF+VmwTMmzcDuW4P9915qBhzpEzMA9yy5DnAnXITYW9dki0L21inVr6sXpZRgxreMR+7eHIxlRuDBtxSh7P8thZkl33OP+LOOgq8bBuAQsreuHeo7hKk/mYq9R/cObxZw2lF387/dXPB1kd7QEYD1169HzGebxImBE6H5mdVE4CVXDMAh49S6NpAZwIETB3DVz6/C9u7tor5ry3YXbV5U0N8KRHxDRwBW7VyFmM/3/AYM3LH1jor9zEK1lZi0YwAOGbfWtXQuDQMGnut6Dne/cHdBtnsqXbygB0R4Q0cA9vXsK6kEc3bwbMV+ZtZtykQMwCGjcopGKptC16kupceL7IaOACycthAxxNAQ8/fPPIsstr69tUJXRTSCAVgz+xCYjsUdMJYZOL70OGZ/bDamjJ/i+HUG5ClUsimJ9devh7HMCM1iUrWZNXIDRklZ8PQJ0ytwVf5E6iBOKgkDsGayITBrd6/F9u7tOHDigO/HrPfaL1DYEVIKlSOkqqWnh8G4VjEAayQbjaiavcVHxTFl/BTHt9j1XPsFijtJvCQaEwX/Pyo2KjTdEFY1tZWZGIB1kvXtqmZv6Vwa/9v3v45Bup5rv36HII1pHlPUrlbpdxE1lcmmUuJMwBUrxJ91dKJFubgVWSN7lmb27a7+r9VK2VsldmrVAr9DkPqH+h1r6pXcjlwzmazTSdm3317zpxwHhRmwJk5ZWn+mH1/f+nW8deKtovubGVqiMYGdX9npuLjm91SHIE+BCIve/l48/dbTvuq3eeQdA3A9v4tQ4nUkETNhTwzAmsiytP6hfqSyqaLbzQDhZ2uyl2qfAlENa3evRTqbxrxPzMMNn7xBaSfcx8792HDHiP2D7zBceB1JVEdnu5WKAVgTWb9vzsh5fq3TFmPZgp6M3/sHodIZdyaXwQO/eQB5I49tv9uG37zzG9d2PdMHgx/UdcdIyVSOJCJXDMCamP2+Xh97bt2DlqaWgq91WiDyO4hn/b71OJ0+rXz/IFQ6497SuQUDQwMAxNFP7515T+nrzgydCbxjxDz5wumjZhbgVI4kIlcMwCEnK1XY28xkC3qyrPN7//G9gmy70oN7ys24VbLn+168D0P5oZHvmVfrA87ms4HXet0W2cpdgAtNcFc5kohcMQCHnKxUYV0gki3ofWPrN3DlT68cHuBjevXdV9HT31N0/1LarlTLCioZuttjWbNnp/vtPboXnSc6fV37tz79LW213nKG8lQyuPvidP5fnZ7tVioG4JBzK1WYQcNtQe/wB4eHB/iYWeeSbUscv1cpmzdUywqyDF3lsezZ890v3F10v7/b8Xe+Syg6N1ocO1ZaEA7dNDXz/L+HHwaWLxd/Hj3KFjRFDMA1QJYlZ42RFWpr1rnn2B7Hx/HbdvXeB+9h+UvLXcsKvf29mPHwjKIt1WbGfajvEOasm4Ouk13SEoU9e37kt48U3e/l7peVr9v04XM+7PtrgqSarZrT00I7H5jD1kvGAFwDnLLkJxY8gQbbX++hU4dw/8v3S6eDPb/oede34va3/kt+vWQ4yFsDvPV+q19ZjT3H9jhm6KlMCpevvRzbu7ejbVObtERhz57N21PZFP7iyb/A7EdnI5Upbt2zi4+K47uzvhuKFrOaOZqeysIz4WrUJ/7xE44bOpoampDNZx3bs8a3jEfP0h5pgF7x0grc99J9mHvpXLR/qR2JlYmChbxkUxJrrluDQ32HcN9L9+G6j1+Hfz/470q70mKIFVxTsimJVX+4Co/sfQRvvP+G9DHMPl+VdjOgersHgwyw9l9Rr8fmrOHwkZ0JxwBcg/Ye3YuZP5up1FNs1RBrwLp567Do8kVFn7Mf+HnTFTdhze41RfcbO3osYrEYTqVPoXlUM4ZyI10JF4+9GF13dKEh1oBMLoPzVp2Hs5mz0uuJj4ojnQtuN1U1gu/EicEvhDEARx8P5QxYaFqBHKzauco1+M6YNMOxvzhv5AvqstYuA3sd9uHXHnZ87IHMwHAnhTX4AmLhbcO+DcOPN5AZcH0eQQTfGZNmVLXkUI0uBLeFuNAt0pErDuMpUWhagRzs790v/ZyZBbZtapP2F9+4+UbsPLJTnD3XtgWAvA5rZ+3DtTNg4K+e+SssmLoA9/znPchDvWth6gVTEUPM9bmZJRCnDL6WhHIhjkrCAFyDOhZ3eN7Hrb/4lSOvFHQZJBoTSuMdmxuaXQMwAAxkB/C1X30NXSedj1Qa3TAa37zqm3j27Wexr2ff8O3dfd1Yc90aTPvQNMx6dJZj9mx2VsyfMh/JZskOrYiJREabSom5EF1dYnfc/PnshFDEGnCJarUO176/Hbc8dctwtjv1gqmYdsE0bHpzU2BblUePGo3B3KD081PGT0H36e6iIDsuPg7X/N412Ny5WXoticYE7vzUnRUZIaki6O6G0P87chpH2djIcZQ2rAGTEqcNEzuP7JQGPLPGOnTPEEbFRil9D7ej4mOI4cIxF0rLIy91v+T6QsARklXEcZRlYwmChsm2NDePasbZ7551fVu/pXMLWppapIPkx8XH4ciSI46PYc26DRjYcXiHtDwy9YKp6P12r89nRhWhMo5y4cLqXlPEMAOmYaqDf5x4ncHm9hj2r21saCw41Tls83ndOmAa6uk3iuMoy1ZP/1wCVYutQCqDf5yonMEmewxZ1h3mU53dulzy+QjUbYPCcZRlYwmiRLXYCqTSPeFEljmrLIh5Zd26FtNIwfz54vw3JxxHqYQZMJWt1My53K8lzTiOsmxsQyPySaUFMah2tEiUM8w+4IMHRdmBfcBFZG1oLEEQKfA742HCBPn9J0wYKWG5PW5k1hLMcZTkGwMwkQK/28tV1whqcS2B1LEGTBQga9Ya5oFNFA4MwEQuzCDqxQy8PT0jQTbMA5soHBiAI4ZZVTBUf46qgZIBlUrBABwxzKqCwZ8jhQEDMBGRJgzAVIRlDn8i0y5GocMAXIe8AmzY3p6H/QWBrWRUKvYBR0hQwSZsAdaLjuut9LHxzJoJYAYcSrKMTyXYhC07rHb2qitb9pqOZxiFH8yaCWAADqWgsrpKZoeqga3a2avq9ws6Az12rDjIMtiSFwbgGueUCQYtjGULGfu7CTM7ZUmAdGAApsA4vf0POzMQR+lFhGoHAzAVKTUbZBAj8ocBmAqYoxLtdUwvlcx2a/H4JyKAbWhkYQ20fufflioWK5yP6yTMi1h8AaByMACHkNsw72qp5vfX/VxVROJkCoocliBCyK2lSbXfNGrCuMONqNIYgCNGtd806m+Nq5UVmz8n1plJB5YgapRT3dSrrmsupNVywJG9OwhznZlqFwNwHbEGGbeuhSCzTzPgRaEnmKjaWIKgkoQ1S2YpgaKEAZgceQUysxYdxOMFiTMZKEpYgiBHQQcrp8djWYLqHTNg0oblAqp3zIBJG5YEqN4xA65TzD6J9GMGXKeCyj7dtk0zkBO5YwCmsrCMQFQ6liCIiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDSJGYahfudYrBdAd+Uuh4ioJn3MMIwL7Df6CsBERBQcliCIiDRhACYi0oQBmIhIEwZgIiJNGICJiDRhACYi0oQBmIhIEwZgIiJNGICJiDT5P9tqo5uP/yk8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[0, :N], X[1, :N], 'bs', markersize = 7);\n",
    "plt.plot(X[0, N:2*N], X[1, N:2*N], 'ro', markersize = 7);\n",
    "plt.plot(X[0, 2*N:], X[1, 2*N:], 'g^', markersize = 7);\n",
    "# plt.axis('off')\n",
    "plt.xlim([-1.5, 1.5])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_xaxis().set_ticks([])\n",
    "cur_axes.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "plt.savefig('EX.png', bbox_inches='tight', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100 # number of points per class\n",
    "d0 = 2 # dimensionality\n",
    "C = 3 # number of classes\n",
    "X = np.zeros((d0, N*C)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*C, dtype='uint8') # class labels\n",
    "\n",
    "for j in range(C):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "  X[:,ix] = np.c_[r*np.sin(t), r*np.cos(t)].T\n",
    "  y[ix] = j\n",
    "# lets visualize the data:\n",
    "# plt.scatter(X[:N, 0], X[:N, 1], c=y[:N], s=40, cmap=plt.cm.Spectral)\n",
    "\n",
    "plt.plot(X[0, :N], X[1, :N], 'bs', markersize = 7);\n",
    "plt.plot(X[0, N:2*N], X[1, N:2*N], 'ro', markersize = 7);\n",
    "plt.plot(X[0, 2*N:], X[1, 2*N:], 'g^', markersize = 7);\n",
    "# plt.axis('off')\n",
    "plt.xlim([-1.5, 1.5])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_xaxis().set_ticks([])\n",
    "cur_axes.axes.get_yaxis().set_ticks([])\n",
    "\n",
    "plt.savefig('EX.png', bbox_inches='tight', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(V):\n",
    "    e_V = np.exp(V - np.max(V, axis = 0, keepdims = True))\n",
    "    Z = e_V / e_V.sum(axis = 0)\n",
    "    return Z\n",
    "\n",
    "## One-hot coding\n",
    "from scipy import sparse\n",
    "def convert_labels(y, C = 3):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y),\n",
    "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y\n",
    "\n",
    "# cost or loss function\n",
    "def cost(Y, Yhat):\n",
    "    return -np.sum(Y*np.log(Yhat))/Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chương trình chính: lớp vào 2 nút, lớp ẩn h nút, lớp ra 3 nút"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = 2\n",
    "d1 = h = 50 # size of hidden layer\n",
    "d2 = C = 3\n",
    "# initialize parameters randomly\n",
    "W1 = 0.01*np.random.randn(d0, d1)\n",
    "b1 = np.zeros((d1, 1))\n",
    "W2 = 0.01*np.random.randn(d1, d2)\n",
    "b2 = np.zeros((d2, 1))\n",
    "\n",
    "Y = convert_labels(y, C)\n",
    "N = X.shape[1]\n",
    "eta = 1 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.11563219e+00,  6.66182614e-01, -7.19147766e-02,\n",
       "         4.90241749e+00,  2.00591562e+00,  2.40022960e+00,\n",
       "         7.06748004e+00, -1.64224224e+00,  8.15353397e-01,\n",
       "        -3.52477607e-03, -9.42803026e+00,  7.74978313e-01,\n",
       "        -1.96973118e+00,  3.09345032e+00, -1.80066721e+00,\n",
       "        -1.85701573e-01, -1.09887013e+00,  5.33268339e+00,\n",
       "        -1.14885367e+00,  1.66536025e+00,  2.34778014e+00,\n",
       "        -3.01493616e-03,  4.82681287e+00,  3.02154543e+00,\n",
       "        -1.48017860e+00,  7.14756944e-01,  8.33110352e-01,\n",
       "         3.96888817e-01,  1.17587868e+01, -1.58570405e+00,\n",
       "         1.25952726e+00, -3.03699661e+00, -1.20318875e-01,\n",
       "         1.77185083e+00,  5.55013778e-02, -1.80180120e+00,\n",
       "        -1.81523377e-01,  5.47531849e-01, -2.59643218e+00,\n",
       "         1.89045251e+00, -8.30942677e-01,  4.38174405e+00,\n",
       "         3.40820257e+00, -9.78220223e-01, -6.11977183e-01,\n",
       "        -2.21710583e-01,  1.58505008e+00,  8.99284074e-04,\n",
       "        -6.93916626e-01,  8.69200236e-01],\n",
       "       [ 5.51050713e-01,  3.69197721e-01,  3.75539632e-03,\n",
       "         8.85114231e-01,  9.41385343e-01, -2.23161152e+00,\n",
       "         6.25290434e+00,  2.87670218e-01,  4.76665335e-01,\n",
       "        -1.38495514e-03, -1.33914052e-01, -4.01094986e-02,\n",
       "         4.25738718e-01,  6.33254456e-01,  3.36690885e-01,\n",
       "         2.02865039e-04, -5.81287272e+00, -5.48528772e+00,\n",
       "         3.80592976e-01,  9.20870005e-01,  1.33404653e+00,\n",
       "        -4.37767495e-03,  9.13286165e-01, -5.30296973e-01,\n",
       "         1.05396220e+00,  4.09785696e-01, -1.43753698e+00,\n",
       "        -6.85534447e-01, -6.08152268e-01,  3.48180299e-01,\n",
       "         5.65658008e-01,  5.43272201e-01,  3.27896832e-03,\n",
       "        -4.29886865e+00,  1.31879392e-01,  3.14484939e-01,\n",
       "        -1.03277245e+00, -5.77156434e-01,  5.55495889e-01,\n",
       "         3.58086487e+00,  2.76577543e-01,  2.56023494e+00,\n",
       "        -3.55399701e+00,  3.17027827e-01,  1.98303975e-01,\n",
       "         6.65641005e-02, -1.40232240e+00, -3.64646013e-03,\n",
       "        -7.82944916e+00, -1.59409082e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 1.098667\n",
      "iter 10, loss: 1.096744\n",
      "iter 20, loss: 1.084275\n",
      "iter 30, loss: 1.010536\n",
      "iter 40, loss: 0.842976\n",
      "iter 50, loss: 0.739019\n",
      "iter 60, loss: 0.708339\n",
      "iter 70, loss: 0.696604\n",
      "iter 80, loss: 0.688557\n",
      "iter 90, loss: 0.681562\n",
      "iter 100, loss: 0.674873\n",
      "iter 110, loss: 0.668114\n",
      "iter 120, loss: 0.661275\n",
      "iter 130, loss: 0.654960\n",
      "iter 140, loss: 0.750199\n",
      "iter 150, loss: 0.691113\n",
      "iter 160, loss: 0.687890\n",
      "iter 170, loss: 0.706206\n",
      "iter 180, loss: 0.691124\n",
      "iter 190, loss: 0.691645\n",
      "iter 200, loss: 0.684105\n",
      "iter 210, loss: 0.679347\n",
      "iter 220, loss: 0.672687\n",
      "iter 230, loss: 0.673115\n",
      "iter 240, loss: 0.753796\n",
      "iter 250, loss: 0.660618\n",
      "iter 260, loss: 0.700745\n",
      "iter 270, loss: 0.667803\n",
      "iter 280, loss: 0.629124\n",
      "iter 290, loss: 0.655710\n",
      "iter 300, loss: 0.596434\n",
      "iter 310, loss: 0.576763\n",
      "iter 320, loss: 0.551127\n",
      "iter 330, loss: 0.514478\n",
      "iter 340, loss: 0.627218\n",
      "iter 350, loss: 0.444261\n",
      "iter 360, loss: 0.491041\n",
      "iter 370, loss: 0.460951\n",
      "iter 380, loss: 0.443504\n",
      "iter 390, loss: 0.434930\n",
      "iter 400, loss: 0.433944\n",
      "iter 410, loss: 0.376619\n",
      "iter 420, loss: 0.406168\n",
      "iter 430, loss: 0.381251\n",
      "iter 440, loss: 0.376024\n",
      "iter 450, loss: 0.362526\n",
      "iter 460, loss: 0.338172\n",
      "iter 470, loss: 0.349592\n",
      "iter 480, loss: 0.338905\n",
      "iter 490, loss: 0.330294\n",
      "iter 500, loss: 0.363620\n",
      "iter 510, loss: 0.280489\n",
      "iter 520, loss: 0.284805\n",
      "iter 530, loss: 0.314184\n",
      "iter 540, loss: 0.292811\n",
      "iter 550, loss: 0.286506\n",
      "iter 560, loss: 0.280723\n",
      "iter 570, loss: 0.310473\n",
      "iter 580, loss: 0.278294\n",
      "iter 590, loss: 0.236758\n",
      "iter 600, loss: 0.265762\n",
      "iter 610, loss: 0.312969\n",
      "iter 620, loss: 0.249805\n",
      "iter 630, loss: 0.243134\n",
      "iter 640, loss: 0.254778\n",
      "iter 650, loss: 0.244935\n",
      "iter 660, loss: 0.236626\n",
      "iter 670, loss: 0.234220\n",
      "iter 680, loss: 0.233226\n",
      "iter 690, loss: 0.229673\n",
      "iter 700, loss: 0.214975\n",
      "iter 710, loss: 0.204037\n",
      "iter 720, loss: 0.214114\n",
      "iter 730, loss: 0.241548\n",
      "iter 740, loss: 0.216130\n",
      "iter 750, loss: 0.211719\n",
      "iter 760, loss: 0.207549\n",
      "iter 770, loss: 0.208576\n",
      "iter 780, loss: 0.204378\n",
      "iter 790, loss: 0.192714\n",
      "iter 800, loss: 0.192779\n",
      "iter 810, loss: 0.192127\n",
      "iter 820, loss: 0.177760\n",
      "iter 830, loss: 0.175947\n",
      "iter 840, loss: 0.186468\n",
      "iter 850, loss: 0.177708\n",
      "iter 860, loss: 0.166228\n",
      "iter 870, loss: 0.169369\n",
      "iter 880, loss: 0.171982\n",
      "iter 890, loss: 0.167282\n",
      "iter 900, loss: 0.199368\n",
      "iter 910, loss: 0.302088\n",
      "iter 920, loss: 0.165765\n",
      "iter 930, loss: 0.153061\n",
      "iter 940, loss: 0.146574\n",
      "iter 950, loss: 0.141778\n",
      "iter 960, loss: 0.138241\n",
      "iter 970, loss: 0.135555\n",
      "iter 980, loss: 0.133652\n",
      "iter 990, loss: 0.135250\n",
      "iter 1000, loss: 0.168022\n",
      "iter 1010, loss: 0.218579\n",
      "iter 1020, loss: 0.130276\n",
      "iter 1030, loss: 0.127049\n",
      "iter 1040, loss: 0.125357\n",
      "iter 1050, loss: 0.123858\n",
      "iter 1060, loss: 0.122879\n",
      "iter 1070, loss: 0.123792\n",
      "iter 1080, loss: 0.132875\n",
      "iter 1090, loss: 0.157595\n",
      "iter 1100, loss: 0.132798\n",
      "iter 1110, loss: 0.121016\n",
      "iter 1120, loss: 0.118608\n",
      "iter 1130, loss: 0.118541\n",
      "iter 1140, loss: 0.121096\n",
      "iter 1150, loss: 0.126528\n",
      "iter 1160, loss: 0.126901\n",
      "iter 1170, loss: 0.120535\n",
      "iter 1180, loss: 0.116226\n",
      "iter 1190, loss: 0.114366\n",
      "iter 1200, loss: 0.114168\n",
      "iter 1210, loss: 0.114538\n",
      "iter 1220, loss: 0.114056\n",
      "iter 1230, loss: 0.112457\n",
      "iter 1240, loss: 0.110614\n",
      "iter 1250, loss: 0.108839\n",
      "iter 1260, loss: 0.107696\n",
      "iter 1270, loss: 0.106778\n",
      "iter 1280, loss: 0.105767\n",
      "iter 1290, loss: 0.104897\n",
      "iter 1300, loss: 0.103507\n",
      "iter 1310, loss: 0.102145\n",
      "iter 1320, loss: 0.100598\n",
      "iter 1330, loss: 0.099173\n",
      "iter 1340, loss: 0.097863\n",
      "iter 1350, loss: 0.096430\n",
      "iter 1360, loss: 0.095061\n",
      "iter 1370, loss: 0.093849\n",
      "iter 1380, loss: 0.092671\n",
      "iter 1390, loss: 0.092018\n",
      "iter 1400, loss: 0.091520\n",
      "iter 1410, loss: 0.091001\n",
      "iter 1420, loss: 0.090149\n",
      "iter 1430, loss: 0.089197\n",
      "iter 1440, loss: 0.088166\n",
      "iter 1450, loss: 0.087132\n",
      "iter 1460, loss: 0.086110\n",
      "iter 1470, loss: 0.085121\n",
      "iter 1480, loss: 0.084255\n",
      "iter 1490, loss: 0.083369\n",
      "iter 1500, loss: 0.082532\n",
      "iter 1510, loss: 0.081749\n",
      "iter 1520, loss: 0.081033\n",
      "iter 1530, loss: 0.080312\n",
      "iter 1540, loss: 0.079614\n",
      "iter 1550, loss: 0.078926\n",
      "iter 1560, loss: 0.078252\n",
      "iter 1570, loss: 0.077591\n",
      "iter 1580, loss: 0.076938\n",
      "iter 1590, loss: 0.076286\n",
      "iter 1600, loss: 0.075609\n",
      "iter 1610, loss: 0.074960\n",
      "iter 1620, loss: 0.074323\n",
      "iter 1630, loss: 0.073707\n",
      "iter 1640, loss: 0.073095\n",
      "iter 1650, loss: 0.072495\n",
      "iter 1660, loss: 0.071926\n",
      "iter 1670, loss: 0.071377\n",
      "iter 1680, loss: 0.070824\n",
      "iter 1690, loss: 0.070263\n",
      "iter 1700, loss: 0.069690\n",
      "iter 1710, loss: 0.069123\n",
      "iter 1720, loss: 0.068593\n",
      "iter 1730, loss: 0.068082\n",
      "iter 1740, loss: 0.067594\n",
      "iter 1750, loss: 0.067103\n",
      "iter 1760, loss: 0.066630\n",
      "iter 1770, loss: 0.066166\n",
      "iter 1780, loss: 0.065711\n",
      "iter 1790, loss: 0.065263\n",
      "iter 1800, loss: 0.064825\n",
      "iter 1810, loss: 0.064386\n",
      "iter 1820, loss: 0.063963\n",
      "iter 1830, loss: 0.063550\n",
      "iter 1840, loss: 0.063138\n",
      "iter 1850, loss: 0.062737\n",
      "iter 1860, loss: 0.062341\n",
      "iter 1870, loss: 0.061957\n",
      "iter 1880, loss: 0.061577\n",
      "iter 1890, loss: 0.061205\n",
      "iter 1900, loss: 0.060838\n",
      "iter 1910, loss: 0.060478\n",
      "iter 1920, loss: 0.060122\n",
      "iter 1930, loss: 0.059769\n",
      "iter 1940, loss: 0.059419\n",
      "iter 1950, loss: 0.059074\n",
      "iter 1960, loss: 0.058734\n",
      "iter 1970, loss: 0.058399\n",
      "iter 1980, loss: 0.058066\n",
      "iter 1990, loss: 0.057739\n",
      "iter 2000, loss: 0.057419\n",
      "iter 2010, loss: 0.057101\n",
      "iter 2020, loss: 0.056788\n",
      "iter 2030, loss: 0.056481\n",
      "iter 2040, loss: 0.056177\n",
      "iter 2050, loss: 0.055876\n",
      "iter 2060, loss: 0.055581\n",
      "iter 2070, loss: 0.055287\n",
      "iter 2080, loss: 0.054999\n",
      "iter 2090, loss: 0.054716\n",
      "iter 2100, loss: 0.054435\n",
      "iter 2110, loss: 0.054159\n",
      "iter 2120, loss: 0.053886\n",
      "iter 2130, loss: 0.053617\n",
      "iter 2140, loss: 0.053350\n",
      "iter 2150, loss: 0.053087\n",
      "iter 2160, loss: 0.052827\n",
      "iter 2170, loss: 0.052570\n",
      "iter 2180, loss: 0.052317\n",
      "iter 2190, loss: 0.052064\n",
      "iter 2200, loss: 0.051817\n",
      "iter 2210, loss: 0.051572\n",
      "iter 2220, loss: 0.051333\n",
      "iter 2230, loss: 0.051096\n",
      "iter 2240, loss: 0.050860\n",
      "iter 2250, loss: 0.050631\n",
      "iter 2260, loss: 0.050408\n",
      "iter 2270, loss: 0.050186\n",
      "iter 2280, loss: 0.049950\n",
      "iter 2290, loss: 0.049718\n",
      "iter 2300, loss: 0.049492\n",
      "iter 2310, loss: 0.049268\n",
      "iter 2320, loss: 0.049047\n",
      "iter 2330, loss: 0.048830\n",
      "iter 2340, loss: 0.048616\n",
      "iter 2350, loss: 0.048404\n",
      "iter 2360, loss: 0.048194\n",
      "iter 2370, loss: 0.047988\n",
      "iter 2380, loss: 0.047785\n",
      "iter 2390, loss: 0.047584\n",
      "iter 2400, loss: 0.047385\n",
      "iter 2410, loss: 0.047188\n",
      "iter 2420, loss: 0.046993\n",
      "iter 2430, loss: 0.046800\n",
      "iter 2440, loss: 0.046611\n",
      "iter 2450, loss: 0.046424\n",
      "iter 2460, loss: 0.046239\n",
      "iter 2470, loss: 0.046057\n",
      "iter 2480, loss: 0.045876\n",
      "iter 2490, loss: 0.045699\n",
      "iter 2500, loss: 0.045522\n",
      "iter 2510, loss: 0.045348\n",
      "iter 2520, loss: 0.045175\n",
      "iter 2530, loss: 0.045004\n",
      "iter 2540, loss: 0.044835\n",
      "iter 2550, loss: 0.044667\n",
      "iter 2560, loss: 0.044501\n",
      "iter 2570, loss: 0.044337\n",
      "iter 2580, loss: 0.044175\n",
      "iter 2590, loss: 0.044014\n",
      "iter 2600, loss: 0.043854\n",
      "iter 2610, loss: 0.043697\n",
      "iter 2620, loss: 0.043540\n",
      "iter 2630, loss: 0.043385\n",
      "iter 2640, loss: 0.043232\n",
      "iter 2650, loss: 0.043080\n",
      "iter 2660, loss: 0.042930\n",
      "iter 2670, loss: 0.042781\n",
      "iter 2680, loss: 0.042634\n",
      "iter 2690, loss: 0.042488\n",
      "iter 2700, loss: 0.042344\n",
      "iter 2710, loss: 0.042201\n",
      "iter 2720, loss: 0.042060\n",
      "iter 2730, loss: 0.041921\n",
      "iter 2740, loss: 0.041782\n",
      "iter 2750, loss: 0.041646\n",
      "iter 2760, loss: 0.041511\n",
      "iter 2770, loss: 0.041377\n",
      "iter 2780, loss: 0.041245\n",
      "iter 2790, loss: 0.041115\n",
      "iter 2800, loss: 0.040985\n",
      "iter 2810, loss: 0.040857\n",
      "iter 2820, loss: 0.040730\n",
      "iter 2830, loss: 0.040605\n",
      "iter 2840, loss: 0.040481\n",
      "iter 2850, loss: 0.040358\n",
      "iter 2860, loss: 0.040236\n",
      "iter 2870, loss: 0.040115\n",
      "iter 2880, loss: 0.039996\n",
      "iter 2890, loss: 0.039877\n",
      "iter 2900, loss: 0.039760\n",
      "iter 2910, loss: 0.039644\n",
      "iter 2920, loss: 0.039528\n",
      "iter 2930, loss: 0.039414\n",
      "iter 2940, loss: 0.039301\n",
      "iter 2950, loss: 0.039188\n",
      "iter 2960, loss: 0.039077\n",
      "iter 2970, loss: 0.038967\n",
      "iter 2980, loss: 0.038857\n",
      "iter 2990, loss: 0.038749\n",
      "iter 3000, loss: 0.038641\n",
      "iter 3010, loss: 0.038535\n",
      "iter 3020, loss: 0.038429\n",
      "iter 3030, loss: 0.038324\n",
      "iter 3040, loss: 0.038220\n",
      "iter 3050, loss: 0.038117\n",
      "iter 3060, loss: 0.038015\n",
      "iter 3070, loss: 0.037913\n",
      "iter 3080, loss: 0.037813\n",
      "iter 3090, loss: 0.037713\n",
      "iter 3100, loss: 0.037614\n",
      "iter 3110, loss: 0.037516\n",
      "iter 3120, loss: 0.037419\n",
      "iter 3130, loss: 0.037322\n",
      "iter 3140, loss: 0.037226\n",
      "iter 3150, loss: 0.037131\n",
      "iter 3160, loss: 0.037037\n",
      "iter 3170, loss: 0.036943\n",
      "iter 3180, loss: 0.036850\n",
      "iter 3190, loss: 0.036758\n",
      "iter 3200, loss: 0.036666\n",
      "iter 3210, loss: 0.036575\n",
      "iter 3220, loss: 0.036484\n",
      "iter 3230, loss: 0.036394\n",
      "iter 3240, loss: 0.036305\n",
      "iter 3250, loss: 0.036217\n",
      "iter 3260, loss: 0.036129\n",
      "iter 3270, loss: 0.036042\n",
      "iter 3280, loss: 0.035955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3290, loss: 0.035869\n",
      "iter 3300, loss: 0.035783\n",
      "iter 3310, loss: 0.035698\n",
      "iter 3320, loss: 0.035614\n",
      "iter 3330, loss: 0.035529\n",
      "iter 3340, loss: 0.035446\n",
      "iter 3350, loss: 0.035363\n",
      "iter 3360, loss: 0.035280\n",
      "iter 3370, loss: 0.035199\n",
      "iter 3380, loss: 0.035118\n",
      "iter 3390, loss: 0.035037\n",
      "iter 3400, loss: 0.034958\n",
      "iter 3410, loss: 0.034879\n",
      "iter 3420, loss: 0.034801\n",
      "iter 3430, loss: 0.034723\n",
      "iter 3440, loss: 0.034646\n",
      "iter 3450, loss: 0.034569\n",
      "iter 3460, loss: 0.034493\n",
      "iter 3470, loss: 0.034417\n",
      "iter 3480, loss: 0.034342\n",
      "iter 3490, loss: 0.034267\n",
      "iter 3500, loss: 0.034192\n",
      "iter 3510, loss: 0.034119\n",
      "iter 3520, loss: 0.034045\n",
      "iter 3530, loss: 0.033972\n",
      "iter 3540, loss: 0.033900\n",
      "iter 3550, loss: 0.033828\n",
      "iter 3560, loss: 0.033757\n",
      "iter 3570, loss: 0.033686\n",
      "iter 3580, loss: 0.033616\n",
      "iter 3590, loss: 0.033546\n",
      "iter 3600, loss: 0.033477\n",
      "iter 3610, loss: 0.033408\n",
      "iter 3620, loss: 0.033339\n",
      "iter 3630, loss: 0.033271\n",
      "iter 3640, loss: 0.033204\n",
      "iter 3650, loss: 0.033137\n",
      "iter 3660, loss: 0.033070\n",
      "iter 3670, loss: 0.033004\n",
      "iter 3680, loss: 0.032938\n",
      "iter 3690, loss: 0.032873\n",
      "iter 3700, loss: 0.032808\n",
      "iter 3710, loss: 0.032744\n",
      "iter 3720, loss: 0.032680\n",
      "iter 3730, loss: 0.032616\n",
      "iter 3740, loss: 0.032553\n",
      "iter 3750, loss: 0.032491\n",
      "iter 3760, loss: 0.032428\n",
      "iter 3770, loss: 0.032366\n",
      "iter 3780, loss: 0.032305\n",
      "iter 3790, loss: 0.032244\n",
      "iter 3800, loss: 0.032183\n",
      "iter 3810, loss: 0.032123\n",
      "iter 3820, loss: 0.032063\n",
      "iter 3830, loss: 0.032003\n",
      "iter 3840, loss: 0.031944\n",
      "iter 3850, loss: 0.031885\n",
      "iter 3860, loss: 0.031826\n",
      "iter 3870, loss: 0.031768\n",
      "iter 3880, loss: 0.031710\n",
      "iter 3890, loss: 0.031652\n",
      "iter 3900, loss: 0.031595\n",
      "iter 3910, loss: 0.031539\n",
      "iter 3920, loss: 0.031482\n",
      "iter 3930, loss: 0.031426\n",
      "iter 3940, loss: 0.031370\n",
      "iter 3950, loss: 0.031314\n",
      "iter 3960, loss: 0.031259\n",
      "iter 3970, loss: 0.031204\n",
      "iter 3980, loss: 0.031149\n",
      "iter 3990, loss: 0.031095\n",
      "iter 4000, loss: 0.031041\n",
      "iter 4010, loss: 0.030987\n",
      "iter 4020, loss: 0.030934\n",
      "iter 4030, loss: 0.030881\n",
      "iter 4040, loss: 0.030828\n",
      "iter 4050, loss: 0.030776\n",
      "iter 4060, loss: 0.030723\n",
      "iter 4070, loss: 0.030672\n",
      "iter 4080, loss: 0.030620\n",
      "iter 4090, loss: 0.030569\n",
      "iter 4100, loss: 0.030518\n",
      "iter 4110, loss: 0.030467\n",
      "iter 4120, loss: 0.030416\n",
      "iter 4130, loss: 0.030366\n",
      "iter 4140, loss: 0.030316\n",
      "iter 4150, loss: 0.030267\n",
      "iter 4160, loss: 0.030217\n",
      "iter 4170, loss: 0.030168\n",
      "iter 4180, loss: 0.030120\n",
      "iter 4190, loss: 0.030071\n",
      "iter 4200, loss: 0.030023\n",
      "iter 4210, loss: 0.029975\n",
      "iter 4220, loss: 0.029927\n",
      "iter 4230, loss: 0.029880\n",
      "iter 4240, loss: 0.029833\n",
      "iter 4250, loss: 0.029786\n",
      "iter 4260, loss: 0.029739\n",
      "iter 4270, loss: 0.029693\n",
      "iter 4280, loss: 0.029647\n",
      "iter 4290, loss: 0.029601\n",
      "iter 4300, loss: 0.029555\n",
      "iter 4310, loss: 0.029510\n",
      "iter 4320, loss: 0.029465\n",
      "iter 4330, loss: 0.029420\n",
      "iter 4340, loss: 0.029374\n",
      "iter 4350, loss: 0.029330\n",
      "iter 4360, loss: 0.029285\n",
      "iter 4370, loss: 0.029241\n",
      "iter 4380, loss: 0.029197\n",
      "iter 4390, loss: 0.029153\n",
      "iter 4400, loss: 0.029109\n",
      "iter 4410, loss: 0.029066\n",
      "iter 4420, loss: 0.029023\n",
      "iter 4430, loss: 0.028980\n",
      "iter 4440, loss: 0.028937\n",
      "iter 4450, loss: 0.028895\n",
      "iter 4460, loss: 0.028852\n",
      "iter 4470, loss: 0.028810\n",
      "iter 4480, loss: 0.028768\n",
      "iter 4490, loss: 0.028727\n",
      "iter 4500, loss: 0.028685\n",
      "iter 4510, loss: 0.028644\n",
      "iter 4520, loss: 0.028603\n",
      "iter 4530, loss: 0.028563\n",
      "iter 4540, loss: 0.028522\n",
      "iter 4550, loss: 0.028482\n",
      "iter 4560, loss: 0.028441\n",
      "iter 4570, loss: 0.028402\n",
      "iter 4580, loss: 0.028362\n",
      "iter 4590, loss: 0.028322\n",
      "iter 4600, loss: 0.028283\n",
      "iter 4610, loss: 0.028244\n",
      "iter 4620, loss: 0.028205\n",
      "iter 4630, loss: 0.028166\n",
      "iter 4640, loss: 0.028127\n",
      "iter 4650, loss: 0.028089\n",
      "iter 4660, loss: 0.028051\n",
      "iter 4670, loss: 0.028012\n",
      "iter 4680, loss: 0.027975\n",
      "iter 4690, loss: 0.027937\n",
      "iter 4700, loss: 0.027899\n",
      "iter 4710, loss: 0.027862\n",
      "iter 4720, loss: 0.027825\n",
      "iter 4730, loss: 0.027788\n",
      "iter 4740, loss: 0.027751\n",
      "iter 4750, loss: 0.027715\n",
      "iter 4760, loss: 0.027678\n",
      "iter 4770, loss: 0.027642\n",
      "iter 4780, loss: 0.027606\n",
      "iter 4790, loss: 0.027570\n",
      "iter 4800, loss: 0.027534\n",
      "iter 4810, loss: 0.027499\n",
      "iter 4820, loss: 0.027463\n",
      "iter 4830, loss: 0.027428\n",
      "iter 4840, loss: 0.027393\n",
      "iter 4850, loss: 0.027358\n",
      "iter 4860, loss: 0.027323\n",
      "iter 4870, loss: 0.027289\n",
      "iter 4880, loss: 0.027254\n",
      "iter 4890, loss: 0.027220\n",
      "iter 4900, loss: 0.027186\n",
      "iter 4910, loss: 0.027152\n",
      "iter 4920, loss: 0.027118\n",
      "iter 4930, loss: 0.027085\n",
      "iter 4940, loss: 0.027051\n",
      "iter 4950, loss: 0.027018\n",
      "iter 4960, loss: 0.026984\n",
      "iter 4970, loss: 0.026951\n",
      "iter 4980, loss: 0.026918\n",
      "iter 4990, loss: 0.026886\n",
      "iter 5000, loss: 0.026853\n",
      "iter 5010, loss: 0.026821\n",
      "iter 5020, loss: 0.026788\n",
      "iter 5030, loss: 0.026756\n",
      "iter 5040, loss: 0.026724\n",
      "iter 5050, loss: 0.026692\n",
      "iter 5060, loss: 0.026660\n",
      "iter 5070, loss: 0.026629\n",
      "iter 5080, loss: 0.026597\n",
      "iter 5090, loss: 0.026566\n",
      "iter 5100, loss: 0.026534\n",
      "iter 5110, loss: 0.026503\n",
      "iter 5120, loss: 0.026472\n",
      "iter 5130, loss: 0.026442\n",
      "iter 5140, loss: 0.026411\n",
      "iter 5150, loss: 0.026380\n",
      "iter 5160, loss: 0.026350\n",
      "iter 5170, loss: 0.026319\n",
      "iter 5180, loss: 0.026289\n",
      "iter 5190, loss: 0.026259\n",
      "iter 5200, loss: 0.026229\n",
      "iter 5210, loss: 0.026199\n",
      "iter 5220, loss: 0.026170\n",
      "iter 5230, loss: 0.026140\n",
      "iter 5240, loss: 0.026111\n",
      "iter 5250, loss: 0.026081\n",
      "iter 5260, loss: 0.026052\n",
      "iter 5270, loss: 0.026023\n",
      "iter 5280, loss: 0.025994\n",
      "iter 5290, loss: 0.025965\n",
      "iter 5300, loss: 0.025937\n",
      "iter 5310, loss: 0.025908\n",
      "iter 5320, loss: 0.025880\n",
      "iter 5330, loss: 0.025851\n",
      "iter 5340, loss: 0.025823\n",
      "iter 5350, loss: 0.025795\n",
      "iter 5360, loss: 0.025767\n",
      "iter 5370, loss: 0.025739\n",
      "iter 5380, loss: 0.025712\n",
      "iter 5390, loss: 0.025684\n",
      "iter 5400, loss: 0.025657\n",
      "iter 5410, loss: 0.025629\n",
      "iter 5420, loss: 0.025602\n",
      "iter 5430, loss: 0.025575\n",
      "iter 5440, loss: 0.025548\n",
      "iter 5450, loss: 0.025521\n",
      "iter 5460, loss: 0.025494\n",
      "iter 5470, loss: 0.025468\n",
      "iter 5480, loss: 0.025441\n",
      "iter 5490, loss: 0.025415\n",
      "iter 5500, loss: 0.025388\n",
      "iter 5510, loss: 0.025362\n",
      "iter 5520, loss: 0.025336\n",
      "iter 5530, loss: 0.025310\n",
      "iter 5540, loss: 0.025284\n",
      "iter 5550, loss: 0.025258\n",
      "iter 5560, loss: 0.025232\n",
      "iter 5570, loss: 0.025205\n",
      "iter 5580, loss: 0.025179\n",
      "iter 5590, loss: 0.025152\n",
      "iter 5600, loss: 0.025126\n",
      "iter 5610, loss: 0.025100\n",
      "iter 5620, loss: 0.025075\n",
      "iter 5630, loss: 0.025049\n",
      "iter 5640, loss: 0.025024\n",
      "iter 5650, loss: 0.024998\n",
      "iter 5660, loss: 0.024973\n",
      "iter 5670, loss: 0.024948\n",
      "iter 5680, loss: 0.024923\n",
      "iter 5690, loss: 0.024898\n",
      "iter 5700, loss: 0.024873\n",
      "iter 5710, loss: 0.024849\n",
      "iter 5720, loss: 0.024824\n",
      "iter 5730, loss: 0.024800\n",
      "iter 5740, loss: 0.024775\n",
      "iter 5750, loss: 0.024751\n",
      "iter 5760, loss: 0.024727\n",
      "iter 5770, loss: 0.024703\n",
      "iter 5780, loss: 0.024679\n",
      "iter 5790, loss: 0.024655\n",
      "iter 5800, loss: 0.024631\n",
      "iter 5810, loss: 0.024608\n",
      "iter 5820, loss: 0.024584\n",
      "iter 5830, loss: 0.024561\n",
      "iter 5840, loss: 0.024537\n",
      "iter 5850, loss: 0.024514\n",
      "iter 5860, loss: 0.024491\n",
      "iter 5870, loss: 0.024468\n",
      "iter 5880, loss: 0.024445\n",
      "iter 5890, loss: 0.024422\n",
      "iter 5900, loss: 0.024399\n",
      "iter 5910, loss: 0.024376\n",
      "iter 5920, loss: 0.024354\n",
      "iter 5930, loss: 0.024331\n",
      "iter 5940, loss: 0.024308\n",
      "iter 5950, loss: 0.024286\n",
      "iter 5960, loss: 0.024264\n",
      "iter 5970, loss: 0.024242\n",
      "iter 5980, loss: 0.024219\n",
      "iter 5990, loss: 0.024197\n",
      "iter 6000, loss: 0.024175\n",
      "iter 6010, loss: 0.024153\n",
      "iter 6020, loss: 0.024132\n",
      "iter 6030, loss: 0.024110\n",
      "iter 6040, loss: 0.024088\n",
      "iter 6050, loss: 0.024067\n",
      "iter 6060, loss: 0.024045\n",
      "iter 6070, loss: 0.024024\n",
      "iter 6080, loss: 0.024002\n",
      "iter 6090, loss: 0.023981\n",
      "iter 6100, loss: 0.023960\n",
      "iter 6110, loss: 0.023939\n",
      "iter 6120, loss: 0.023918\n",
      "iter 6130, loss: 0.023897\n",
      "iter 6140, loss: 0.023876\n",
      "iter 6150, loss: 0.023855\n",
      "iter 6160, loss: 0.023834\n",
      "iter 6170, loss: 0.023814\n",
      "iter 6180, loss: 0.023793\n",
      "iter 6190, loss: 0.023773\n",
      "iter 6200, loss: 0.023752\n",
      "iter 6210, loss: 0.023732\n",
      "iter 6220, loss: 0.023711\n",
      "iter 6230, loss: 0.023689\n",
      "iter 6240, loss: 0.023668\n",
      "iter 6250, loss: 0.023647\n",
      "iter 6260, loss: 0.023627\n",
      "iter 6270, loss: 0.023606\n",
      "iter 6280, loss: 0.023585\n",
      "iter 6290, loss: 0.023565\n",
      "iter 6300, loss: 0.023544\n",
      "iter 6310, loss: 0.023524\n",
      "iter 6320, loss: 0.023504\n",
      "iter 6330, loss: 0.023483\n",
      "iter 6340, loss: 0.023463\n",
      "iter 6350, loss: 0.023443\n",
      "iter 6360, loss: 0.023423\n",
      "iter 6370, loss: 0.023403\n",
      "iter 6380, loss: 0.023384\n",
      "iter 6390, loss: 0.023364\n",
      "iter 6400, loss: 0.023344\n",
      "iter 6410, loss: 0.023325\n",
      "iter 6420, loss: 0.023305\n",
      "iter 6430, loss: 0.023286\n",
      "iter 6440, loss: 0.023267\n",
      "iter 6450, loss: 0.023247\n",
      "iter 6460, loss: 0.023228\n",
      "iter 6470, loss: 0.023209\n",
      "iter 6480, loss: 0.023190\n",
      "iter 6490, loss: 0.023171\n",
      "iter 6500, loss: 0.023153\n",
      "iter 6510, loss: 0.023134\n",
      "iter 6520, loss: 0.023115\n",
      "iter 6530, loss: 0.023097\n",
      "iter 6540, loss: 0.023078\n",
      "iter 6550, loss: 0.023059\n",
      "iter 6560, loss: 0.023041\n",
      "iter 6570, loss: 0.023023\n",
      "iter 6580, loss: 0.023004\n",
      "iter 6590, loss: 0.022986\n",
      "iter 6600, loss: 0.022968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 6610, loss: 0.022950\n",
      "iter 6620, loss: 0.022932\n",
      "iter 6630, loss: 0.022914\n",
      "iter 6640, loss: 0.022896\n",
      "iter 6650, loss: 0.022878\n",
      "iter 6660, loss: 0.022860\n",
      "iter 6670, loss: 0.022842\n",
      "iter 6680, loss: 0.022824\n",
      "iter 6690, loss: 0.022807\n",
      "iter 6700, loss: 0.022789\n",
      "iter 6710, loss: 0.022772\n",
      "iter 6720, loss: 0.022754\n",
      "iter 6730, loss: 0.022737\n",
      "iter 6740, loss: 0.022719\n",
      "iter 6750, loss: 0.022702\n",
      "iter 6760, loss: 0.022685\n",
      "iter 6770, loss: 0.022667\n",
      "iter 6780, loss: 0.022650\n",
      "iter 6790, loss: 0.022633\n",
      "iter 6800, loss: 0.022616\n",
      "iter 6810, loss: 0.022599\n",
      "iter 6820, loss: 0.022582\n",
      "iter 6830, loss: 0.022565\n",
      "iter 6840, loss: 0.022548\n",
      "iter 6850, loss: 0.022532\n",
      "iter 6860, loss: 0.022515\n",
      "iter 6870, loss: 0.022498\n",
      "iter 6880, loss: 0.022482\n",
      "iter 6890, loss: 0.022465\n",
      "iter 6900, loss: 0.022449\n",
      "iter 6910, loss: 0.022432\n",
      "iter 6920, loss: 0.022416\n",
      "iter 6930, loss: 0.022400\n",
      "iter 6940, loss: 0.022383\n",
      "iter 6950, loss: 0.022367\n",
      "iter 6960, loss: 0.022351\n",
      "iter 6970, loss: 0.022335\n",
      "iter 6980, loss: 0.022319\n",
      "iter 6990, loss: 0.022303\n",
      "iter 7000, loss: 0.022287\n",
      "iter 7010, loss: 0.022271\n",
      "iter 7020, loss: 0.022256\n",
      "iter 7030, loss: 0.022240\n",
      "iter 7040, loss: 0.022224\n",
      "iter 7050, loss: 0.022209\n",
      "iter 7060, loss: 0.022193\n",
      "iter 7070, loss: 0.022177\n",
      "iter 7080, loss: 0.022162\n",
      "iter 7090, loss: 0.022146\n",
      "iter 7100, loss: 0.022131\n",
      "iter 7110, loss: 0.022116\n",
      "iter 7120, loss: 0.022100\n",
      "iter 7130, loss: 0.022085\n",
      "iter 7140, loss: 0.022070\n",
      "iter 7150, loss: 0.022055\n",
      "iter 7160, loss: 0.022039\n",
      "iter 7170, loss: 0.022024\n",
      "iter 7180, loss: 0.022009\n",
      "iter 7190, loss: 0.021994\n",
      "iter 7200, loss: 0.021979\n",
      "iter 7210, loss: 0.021964\n",
      "iter 7220, loss: 0.021950\n",
      "iter 7230, loss: 0.021935\n",
      "iter 7240, loss: 0.021920\n",
      "iter 7250, loss: 0.021905\n",
      "iter 7260, loss: 0.021890\n",
      "iter 7270, loss: 0.021876\n",
      "iter 7280, loss: 0.021861\n",
      "iter 7290, loss: 0.021846\n",
      "iter 7300, loss: 0.021832\n",
      "iter 7310, loss: 0.021817\n",
      "iter 7320, loss: 0.021803\n",
      "iter 7330, loss: 0.021789\n",
      "iter 7340, loss: 0.021774\n",
      "iter 7350, loss: 0.021760\n",
      "iter 7360, loss: 0.021746\n",
      "iter 7370, loss: 0.021731\n",
      "iter 7380, loss: 0.021717\n",
      "iter 7390, loss: 0.021703\n",
      "iter 7400, loss: 0.021689\n",
      "iter 7410, loss: 0.021675\n",
      "iter 7420, loss: 0.021661\n",
      "iter 7430, loss: 0.021647\n",
      "iter 7440, loss: 0.021633\n",
      "iter 7450, loss: 0.021619\n",
      "iter 7460, loss: 0.021605\n",
      "iter 7470, loss: 0.021591\n",
      "iter 7480, loss: 0.021577\n",
      "iter 7490, loss: 0.021564\n",
      "iter 7500, loss: 0.021550\n",
      "iter 7510, loss: 0.021536\n",
      "iter 7520, loss: 0.021523\n",
      "iter 7530, loss: 0.021509\n",
      "iter 7540, loss: 0.021495\n",
      "iter 7550, loss: 0.021482\n",
      "iter 7560, loss: 0.021468\n",
      "iter 7570, loss: 0.021455\n",
      "iter 7580, loss: 0.021442\n",
      "iter 7590, loss: 0.021428\n",
      "iter 7600, loss: 0.021415\n",
      "iter 7610, loss: 0.021401\n",
      "iter 7620, loss: 0.021388\n",
      "iter 7630, loss: 0.021375\n",
      "iter 7640, loss: 0.021362\n",
      "iter 7650, loss: 0.021349\n",
      "iter 7660, loss: 0.021335\n",
      "iter 7670, loss: 0.021322\n",
      "iter 7680, loss: 0.021309\n",
      "iter 7690, loss: 0.021296\n",
      "iter 7700, loss: 0.021283\n",
      "iter 7710, loss: 0.021270\n",
      "iter 7720, loss: 0.021257\n",
      "iter 7730, loss: 0.021244\n",
      "iter 7740, loss: 0.021232\n",
      "iter 7750, loss: 0.021219\n",
      "iter 7760, loss: 0.021206\n",
      "iter 7770, loss: 0.021193\n",
      "iter 7780, loss: 0.021180\n",
      "iter 7790, loss: 0.021168\n",
      "iter 7800, loss: 0.021155\n",
      "iter 7810, loss: 0.021142\n",
      "iter 7820, loss: 0.021130\n",
      "iter 7830, loss: 0.021117\n",
      "iter 7840, loss: 0.021104\n",
      "iter 7850, loss: 0.021092\n",
      "iter 7860, loss: 0.021079\n",
      "iter 7870, loss: 0.021067\n",
      "iter 7880, loss: 0.021054\n",
      "iter 7890, loss: 0.021042\n",
      "iter 7900, loss: 0.021030\n",
      "iter 7910, loss: 0.021017\n",
      "iter 7920, loss: 0.021005\n",
      "iter 7930, loss: 0.020993\n",
      "iter 7940, loss: 0.020981\n",
      "iter 7950, loss: 0.020969\n",
      "iter 7960, loss: 0.020956\n",
      "iter 7970, loss: 0.020944\n",
      "iter 7980, loss: 0.020932\n",
      "iter 7990, loss: 0.020920\n",
      "iter 8000, loss: 0.020908\n",
      "iter 8010, loss: 0.020896\n",
      "iter 8020, loss: 0.020884\n",
      "iter 8030, loss: 0.020872\n",
      "iter 8040, loss: 0.020860\n",
      "iter 8050, loss: 0.020848\n",
      "iter 8060, loss: 0.020836\n",
      "iter 8070, loss: 0.020824\n",
      "iter 8080, loss: 0.020812\n",
      "iter 8090, loss: 0.020801\n",
      "iter 8100, loss: 0.020789\n",
      "iter 8110, loss: 0.020777\n",
      "iter 8120, loss: 0.020765\n",
      "iter 8130, loss: 0.020754\n",
      "iter 8140, loss: 0.020742\n",
      "iter 8150, loss: 0.020730\n",
      "iter 8160, loss: 0.020719\n",
      "iter 8170, loss: 0.020707\n",
      "iter 8180, loss: 0.020696\n",
      "iter 8190, loss: 0.020684\n",
      "iter 8200, loss: 0.020673\n",
      "iter 8210, loss: 0.020661\n",
      "iter 8220, loss: 0.020650\n",
      "iter 8230, loss: 0.020638\n",
      "iter 8240, loss: 0.020627\n",
      "iter 8250, loss: 0.020616\n",
      "iter 8260, loss: 0.020605\n",
      "iter 8270, loss: 0.020593\n",
      "iter 8280, loss: 0.020582\n",
      "iter 8290, loss: 0.020571\n",
      "iter 8300, loss: 0.020560\n",
      "iter 8310, loss: 0.020549\n",
      "iter 8320, loss: 0.020537\n",
      "iter 8330, loss: 0.020526\n",
      "iter 8340, loss: 0.020515\n",
      "iter 8350, loss: 0.020504\n",
      "iter 8360, loss: 0.020493\n",
      "iter 8370, loss: 0.020482\n",
      "iter 8380, loss: 0.020471\n",
      "iter 8390, loss: 0.020460\n",
      "iter 8400, loss: 0.020449\n",
      "iter 8410, loss: 0.020438\n",
      "iter 8420, loss: 0.020428\n",
      "iter 8430, loss: 0.020417\n",
      "iter 8440, loss: 0.020406\n",
      "iter 8450, loss: 0.020395\n",
      "iter 8460, loss: 0.020384\n",
      "iter 8470, loss: 0.020374\n",
      "iter 8480, loss: 0.020363\n",
      "iter 8490, loss: 0.020352\n",
      "iter 8500, loss: 0.020342\n",
      "iter 8510, loss: 0.020331\n",
      "iter 8520, loss: 0.020320\n",
      "iter 8530, loss: 0.020310\n",
      "iter 8540, loss: 0.020299\n",
      "iter 8550, loss: 0.020289\n",
      "iter 8560, loss: 0.020278\n",
      "iter 8570, loss: 0.020268\n",
      "iter 8580, loss: 0.020257\n",
      "iter 8590, loss: 0.020247\n",
      "iter 8600, loss: 0.020237\n",
      "iter 8610, loss: 0.020226\n",
      "iter 8620, loss: 0.020216\n",
      "iter 8630, loss: 0.020206\n",
      "iter 8640, loss: 0.020195\n",
      "iter 8650, loss: 0.020185\n",
      "iter 8660, loss: 0.020175\n",
      "iter 8670, loss: 0.020165\n",
      "iter 8680, loss: 0.020155\n",
      "iter 8690, loss: 0.020144\n",
      "iter 8700, loss: 0.020134\n",
      "iter 8710, loss: 0.020124\n",
      "iter 8720, loss: 0.020114\n",
      "iter 8730, loss: 0.020104\n",
      "iter 8740, loss: 0.020094\n",
      "iter 8750, loss: 0.020084\n",
      "iter 8760, loss: 0.020074\n",
      "iter 8770, loss: 0.020064\n",
      "iter 8780, loss: 0.020054\n",
      "iter 8790, loss: 0.020044\n",
      "iter 8800, loss: 0.020034\n",
      "iter 8810, loss: 0.020024\n",
      "iter 8820, loss: 0.020015\n",
      "iter 8830, loss: 0.020005\n",
      "iter 8840, loss: 0.019995\n",
      "iter 8850, loss: 0.019985\n",
      "iter 8860, loss: 0.019976\n",
      "iter 8870, loss: 0.019966\n",
      "iter 8880, loss: 0.019956\n",
      "iter 8890, loss: 0.019947\n",
      "iter 8900, loss: 0.019937\n",
      "iter 8910, loss: 0.019927\n",
      "iter 8920, loss: 0.019918\n",
      "iter 8930, loss: 0.019908\n",
      "iter 8940, loss: 0.019898\n",
      "iter 8950, loss: 0.019889\n",
      "iter 8960, loss: 0.019879\n",
      "iter 8970, loss: 0.019870\n",
      "iter 8980, loss: 0.019860\n",
      "iter 8990, loss: 0.019851\n",
      "iter 9000, loss: 0.019842\n",
      "iter 9010, loss: 0.019832\n",
      "iter 9020, loss: 0.019823\n",
      "iter 9030, loss: 0.019813\n",
      "iter 9040, loss: 0.019804\n",
      "iter 9050, loss: 0.019795\n",
      "iter 9060, loss: 0.019785\n",
      "iter 9070, loss: 0.019776\n",
      "iter 9080, loss: 0.019767\n",
      "iter 9090, loss: 0.019758\n",
      "iter 9100, loss: 0.019748\n",
      "iter 9110, loss: 0.019739\n",
      "iter 9120, loss: 0.019730\n",
      "iter 9130, loss: 0.019721\n",
      "iter 9140, loss: 0.019712\n",
      "iter 9150, loss: 0.019702\n",
      "iter 9160, loss: 0.019693\n",
      "iter 9170, loss: 0.019683\n",
      "iter 9180, loss: 0.019674\n",
      "iter 9190, loss: 0.019665\n",
      "iter 9200, loss: 0.019656\n",
      "iter 9210, loss: 0.019646\n",
      "iter 9220, loss: 0.019637\n",
      "iter 9230, loss: 0.019628\n",
      "iter 9240, loss: 0.019619\n",
      "iter 9250, loss: 0.019610\n",
      "iter 9260, loss: 0.019601\n",
      "iter 9270, loss: 0.019592\n",
      "iter 9280, loss: 0.019583\n",
      "iter 9290, loss: 0.019574\n",
      "iter 9300, loss: 0.019565\n",
      "iter 9310, loss: 0.019556\n",
      "iter 9320, loss: 0.019547\n",
      "iter 9330, loss: 0.019538\n",
      "iter 9340, loss: 0.019529\n",
      "iter 9350, loss: 0.019520\n",
      "iter 9360, loss: 0.019511\n",
      "iter 9370, loss: 0.019502\n",
      "iter 9380, loss: 0.019494\n",
      "iter 9390, loss: 0.019485\n",
      "iter 9400, loss: 0.019476\n",
      "iter 9410, loss: 0.019467\n",
      "iter 9420, loss: 0.019459\n",
      "iter 9430, loss: 0.019450\n",
      "iter 9440, loss: 0.019441\n",
      "iter 9450, loss: 0.019433\n",
      "iter 9460, loss: 0.019424\n",
      "iter 9470, loss: 0.019415\n",
      "iter 9480, loss: 0.019407\n",
      "iter 9490, loss: 0.019398\n",
      "iter 9500, loss: 0.019390\n",
      "iter 9510, loss: 0.019381\n",
      "iter 9520, loss: 0.019373\n",
      "iter 9530, loss: 0.019364\n",
      "iter 9540, loss: 0.019356\n",
      "iter 9550, loss: 0.019347\n",
      "iter 9560, loss: 0.019339\n",
      "iter 9570, loss: 0.019330\n",
      "iter 9580, loss: 0.019322\n",
      "iter 9590, loss: 0.019313\n",
      "iter 9600, loss: 0.019305\n",
      "iter 9610, loss: 0.019297\n",
      "iter 9620, loss: 0.019288\n",
      "iter 9630, loss: 0.019280\n",
      "iter 9640, loss: 0.019272\n",
      "iter 9650, loss: 0.019264\n",
      "iter 9660, loss: 0.019255\n",
      "iter 9670, loss: 0.019247\n",
      "iter 9680, loss: 0.019239\n",
      "iter 9690, loss: 0.019231\n",
      "iter 9700, loss: 0.019223\n",
      "iter 9710, loss: 0.019214\n",
      "iter 9720, loss: 0.019206\n",
      "iter 9730, loss: 0.019198\n",
      "iter 9740, loss: 0.019190\n",
      "iter 9750, loss: 0.019182\n",
      "iter 9760, loss: 0.019174\n",
      "iter 9770, loss: 0.019166\n",
      "iter 9780, loss: 0.019158\n",
      "iter 9790, loss: 0.019150\n",
      "iter 9800, loss: 0.019142\n",
      "iter 9810, loss: 0.019134\n",
      "iter 9820, loss: 0.019126\n",
      "iter 9830, loss: 0.019118\n",
      "iter 9840, loss: 0.019110\n",
      "iter 9850, loss: 0.019102\n",
      "iter 9860, loss: 0.019094\n",
      "iter 9870, loss: 0.019087\n",
      "iter 9880, loss: 0.019079\n",
      "iter 9890, loss: 0.019071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 9900, loss: 0.019063\n",
      "iter 9910, loss: 0.019055\n",
      "iter 9920, loss: 0.019047\n",
      "iter 9930, loss: 0.019040\n",
      "iter 9940, loss: 0.019032\n",
      "iter 9950, loss: 0.019024\n",
      "iter 9960, loss: 0.019017\n",
      "iter 9970, loss: 0.019009\n",
      "iter 9980, loss: 0.019001\n",
      "iter 9990, loss: 0.018993\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    ## Feedforward\n",
    "    Z1 = np.dot(W1.T, X) + b1\n",
    "    A1 = np.maximum(Z1, 0)\n",
    "    Z2 = np.dot(W2.T, A1) + b2\n",
    "    Yhat = softmax(Z2)\n",
    "\n",
    "    # print loss after each 1000 iterations\n",
    "    if i %10 == 0:\n",
    "        # compute the loss: average cross-entropy loss\n",
    "        loss = cost(Y, Yhat)\n",
    "        print(\"iter %d, loss: %f\" %(i, loss))\n",
    "\n",
    "    # backpropagation\n",
    "    E2 = (Yhat - Y )/N\n",
    "    dW2 = np.dot(A1, E2.T)\n",
    "    db2 = np.sum(E2, axis = 1, keepdims = True)\n",
    "    E1 = np.dot(W2, E2)\n",
    "    E1[Z1 <= 0] = 0 # gradient of ReLU\n",
    "    dW1 = np.dot(X, E1.T)\n",
    "    db1 = np.sum(E1, axis = 1, keepdims = True)\n",
    "\n",
    "    # Gradient Descent update\n",
    "    W1 += -eta*dW1\n",
    "    b1 += -eta*db1\n",
    "    W2 += -eta*dW2\n",
    "    b2 += -eta*db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thử trọng số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90203675 -1.22056746 -0.29834118 -0.20411774  0.03966303]\n",
      " [ 2.03265835  1.14509103  0.36212001  0.58340827  0.17234494]]\n"
     ]
    }
   ],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Độ chính xác theo accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 99.33 %\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1.T, X) + b1\n",
    "A1 = np.maximum(Z1, 0)\n",
    "Z2 = np.dot(W2.T, A1) + b2\n",
    "predicted_class = np.argmax(Z2, axis=0)\n",
    "print('training accuracy: %.2f %%' % (100*np.mean(predicted_class == y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
