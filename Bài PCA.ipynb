{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Về thuật toán PCA (Principal Component Analysys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mục đích của thuật toán PCA là phân tích tìm ra những thành phần chính, quan trọng nhất của dữ liệu nhiều chiều có thể đại diện cho dữ liệu, không làm mất mát quá nhiều thông tin để tiện lợi trong quá trình xử lý dữ liệu.\n",
    "\n",
    "Các thuộc tính của dữ liệu trong các bài toán thực tế thường khá lớn. Ví dụ đối với ảnh có thể đến hàng ngàn chiều, tương ứng với độ phân giải của ảnh, số kênh màu của ảnh. Trường hợp đơn giản như dữ liệu hoa Iris đã có 4 thuộc tính: chiều dài, chiều rộng của cánh hoa, chiều dài, chiều rộng của đài hoa. Số thuộc tính lớn như vậy gây khó khăn cho việc xử lý, từ đơn giản như biểu diễn trực quan dữ liệu bằng đồ thị đến phức tạp hơn như khi cần tính toán trong học máy.\n",
    "\n",
    "Vẫn với yêu cầu của bài toán trên dữ liệu gốc, không thay đổi mục tiêu ban đầu, nhưng nếu có dữ liệu thu gọn thì việc xử lý sẽ hiệu quả hơn, nhanh hơn, thậm chí có thể trực quan hơn. Tuy nhiên, khi thu gọn dữ liệu không được để mất mát quá nhiều thông tin làm ảnh hưởng đến kết quả của bài toán. Một trong những cách thu gọn dữ liệu ở đây là giảm chiều dữ liệu, bỏ bớt, thu gom các thuộc tính (Dimensionality Reduction).\n",
    "\n",
    "Một cách hình thức hóa, mỗi điểm dữ liệu $x\\in R^D$, với $D$ lớn hoặc rất lớn, chúng ta sẽ tìm một điểm thay thế cho nó là $z\\in R^K$, với $K<D$ nhưng vẫn giữ được thông tin cần thiết cho $x$. PCA - Principal Component Analysys là một phương pháp như vậy, tìm ra, giữ lại những thành phần quan trọng và lược bỏ những thành phần không hoặc ít quan trọng hơn. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ví dụ đơn giản về giảm chiều dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong mặt phẳng, ta xét các điểm dữ liệu (1,1), (2,2), (3,3) trong hệ tọa độ Oxy thông thường. Không gian đang xét là không gian 2 chiều có hệ vector cơ sở là (1,0), (0,1).\n",
    "\n",
    "Cũng các điểm dữ liệu này nhưng nếu ta chọn hệ vector cơ sở khác (1,1), (-1,1), khi đó đối với hệ trục mới này các điểm sẽ trên lần lượt có tọa độ mới (0, 1.41), (0,2.82), (0,4.23). Thành phần toạ độ thứ nhất đều bằng 0, ta có thể bỏ qua, chỉ cần xét thành phần tọa độ thứ hai. Để ý rằng, thông tin về khoảng cách giữa các điểm dữ liệu vẫn được bảo toàn, không bị mất mát, khoảng cách giữa các điểm liền kề là 1.41, giống như trên hệ tọa độ cũ. Tuy nhiên, trên hệ tọa độ cũ để nói đến khoảng cách như vậy, ta sẽ nói rằng chúng cách nhau 1 đơn vị theo chiều thứ nhất và cách nhau 1 đơn vị theo chiều thứ hai. Bây giờ, với hệ tọa độ mới, chúng ta chỉ cần nói rằng chúng cách nhau 1.41 theo một thành phần và chỉ một thành phần này là đủ. Như vậy chúng ta đã giảm chiều dữ liệu nhưng không làm mất mát thông tin. \n",
    "\n",
    "Ví dụ này xét một trường hợp quá đặc biệt, trong thực tế dữ liệu sẽ phức tạp hơn nhiều và chúng ta sẽ xem xét phương pháp giải quyết bắt đầu từ trường hợp đặc biệt này.\n",
    "\n",
    "$A=\\matrix[[1,1], [2,2], [3,3]]$\n",
    "\n",
    "$$ A=\\left[\\begin{matrix} 1&1\\\\ 2&2\\\\3&3\\end{matrix}\\right]$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
